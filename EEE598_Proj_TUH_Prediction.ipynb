{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQ5Xpjq3VNtH0rfbhdAkhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpmadabhu/EEE598_proj_tuh_eeg/blob/main/EEE598_Proj_TUH_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TUSZ Preprocessing Pipeline – Smart Canonical Montage (Reference Alignment)\n",
        "\n",
        "## High-level\n",
        "This notebook builds a seizure vs background window dataset from TUH Seizure Corpus (TUSZ) tcp-bipolar EEG.\n",
        "\n",
        "It does:\n",
        "- Recursively walks `train/`, `dev/`, or `eval` under `ROOT_DIR`.\n",
        "- For each EDF:\n",
        "  - Load EEG + its seizure annotations (.csv).\n",
        "  - Bandpass 0.5–40 Hz using a Kaiser FIR, zero-phase (`filtfilt`).\n",
        "  - Downsample to 250 Hz *if* original fs is higher; never upsample.\n",
        "  - Robust z-score per channel (median/IQR).\n",
        "  - Slice into 10 s windows with 5 s hop.\n",
        "  - Label each window seizure(1) or background(0), pooling all seizure subtypes.\n",
        "- Skips recordings that are too short for `filtfilt` padding.\n",
        "- Saves:\n",
        "  - `split_windows.npz` with windows, labels, and metadata.\n",
        "  - `qc_window.png` plotting an informative example window.\n",
        "  - `class_balance.png` showing seizure/background counts.\n",
        "\n",
        "## Smart Canonical Montage\n",
        "We do **not** force a giant hard-coded canonical bipolar channel list upfront.\n",
        "Instead we learn a canonical layout from *inside the split*:\n",
        "\n",
        "1. The **first usable recording** becomes our **reference layout**.\n",
        "   - We store its channel names/ordering. Call this `ref_ch_names`.\n",
        "2. Every later recording is aligned to that same reference layout:\n",
        "   - For each reference channel name (like `FP1-F7`), we try to find the best-matching channel name in the new recording using a robust normalizer.\n",
        "   - If found, we copy that channel.\n",
        "   - If missing, we fill zeros in that row.\n",
        "3. We compute a **coverage ratio** = fraction of reference channels we could actually fill with real data from this recording.\n",
        "   - If coverage is too low (default <30%), we SKIP that recording to avoid mostly-zero data.\n",
        "\n",
        "So we get:\n",
        "- Consistent `[C, T]` across all recordings (good for training).\n",
        "- Mostly real EEG, not all zeros.\n",
        "- QC plot that reflects the aligned tensors you’ll actually train on.\n",
        "\n",
        "## Prediction Labeling\n",
        "\n",
        "- **Positive (y = 1)**: **pre-ictal** windows only — the interval *before onset* where a predictor should alarm.  \n",
        "  Defined per seizure as **[onset − SOP_MIN, onset − SPH_MIN]**.\n",
        "- **Negative (y = 0)**: **interictal** background **plus** a short **early-ictal** portion immediately after onset:  \n",
        "  **[onset, min(onset + EARLY_ICTAL_KEPT_S, offset)]**.\n",
        "- **Ignored** (not used for training): the **prediction horizon** just before onset **(onset − SPH_MIN, onset)**, the **remainder of ictal** after the early-ictal portion, and an optional **post-ictal** buffer **(offset, offset + POSTICTAL_BUFFER_S]** when enabled.\n",
        "- **Artifacts**: windows overlapping artifact intervals are **dropped**; if `KEEP_PREICTAL_EVEN_IF_ARTIFACT = True`, pre-ictal windows are **kept** even when overlapping artifacts (positives are scarce).\n",
        "\n",
        "### Timing variables (all in seconds)\n",
        "- `SOP_MIN` — Seizure Occurrence Period look-back (e.g., 30*60).  \n",
        "- `SPH_MIN` — Seizure Prediction Horizon “no-alarm” band (e.g., 5*60).  \n",
        "- `EARLY_ICTAL_KEPT_S` — early-ictal kept as **negative** (e.g., 10).  \n",
        "- `POSTICTAL_BUFFER_S` — optional ignore after offset (0 disables).  \n",
        "- `KEEP_PREICTAL_EVEN_IF_ARTIFACT` — keep/don’t keep pre-ictal windows that overlap artifacts.\n",
        "\n",
        "### Note on normalization (robust z)\n",
        "Pre-ictal windows can be very quiet (IQR≈0). Robust z-score uses a **safe denominator**  \n",
        "`denom = max(IQR, 0.1*STD, 1e-6)` to prevent extreme amplitudes while preserving behavior elsewhere.\n",
        "\n",
        "## Runtime knobs\n",
        "- `MAX_SUBJECTS`: cap how many subjects to include (fast debug).\n",
        "- `MAX_RECORDINGS`: cap recordings per subject (or overall).\n",
        "- `NUM_TAPS`: FIR length. Shorter => fewer clips skipped for being \"too short\".\n",
        "- `GROUP_MODE`: iterate by `\"subject\"` (recommended) or just all EDFs (`\"recording\"`).\n",
        "- `min_coverage`: skip a recording if < this fraction of reference channels could be mapped."
      ],
      "metadata": {
        "id": "xdPVz37Se9pN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KroXjzjexGg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import mne\n",
        "from scipy.signal import firwin, filtfilt, resample_poly\n",
        "from math import gcd\n",
        "import io, re\n",
        "import random\n",
        "\n",
        "# ------------------ USER CONFIG ------------------\n",
        "# Point this at the root of the TUSZ split folders that contain train/dev/eval\n",
        "ROOT_DIR = Path(\"Enter the mounted onedrive location of the edf folder of tusz database\").expanduser().resolve()\n",
        "\n",
        "# Output directory for NPZ + plots\n",
        "OUT_DIR  = Path(\"output folder to save the windows ans coverage stats\").expanduser().resolve()\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Windowing params\n",
        "WIN_LEN_S = 10.0   # seconds per window\n",
        "HOP_S     = 5.0    # seconds hop (50% overlap)\n",
        "\n",
        "# --- Prediction labeling policy (all times in SECONDS) ---\n",
        "SOP_MIN = 30 * 60          # 30 minutes before seizure onset (pre-ictal start)\n",
        "SPH_MIN = 5  * 60          # 5 minutes before onset (prediction horizon, ignored)\n",
        "EARLY_ICTAL_KEPT_S = 10    # first 10 s of ictal treated as NEGATIVE (y=0)\n",
        "POSTICTAL_BUFFER_S = 0     # ignore after offset (0 disables)\n",
        "KEEP_PREICTAL_EVEN_IF_ARTIFACT = True  # keep pre-ictal even if overlapping artifacts\n",
        "\n",
        "# DSP params\n",
        "NUM_TAPS  = 1001    # Kaiser FIR taps for bandpass 0.5-40Hz (shorter -> fewer skips)\n",
        "TARGET_FS = 250.0  # We'll downsample to 250 Hz if fs_orig > 250 Hz; never upsample\n",
        "\n",
        "# Runtime limiting params\n",
        "MAX_SUBJECTS   = 10        # limit number of subjects used (debug speed). None = no explicit cap\n",
        "MAX_RECORDINGS = 10      # max recordings per subject / overall. None = no explicit cap\n",
        "GROUP_MODE     = \"subject\" # \"subject\" or \"recording\"\n",
        "\n",
        "# Seizure subtype labels we consider \"seizure\" (label=1)\n",
        "# Everything else becomes background (label=0)\n",
        "SEIZURE_LABELS = {\n",
        "    'seiz','fnsz','gnsz','spsz','cpsz','absz',\n",
        "    'tnsz','cnsz','tcsz','atsz','mysz'\n",
        "}\n",
        "\n",
        "# Artifact / noise labels in TUSZ annotations.\n",
        "# Based on TUSZ event map, includes muscle, eye movement, chewing, shiver,\n",
        "# electrode pops, and combos. :contentReference[oaicite:0]{index=0}\n",
        "ARTIFACT_LABELS = {\n",
        "    'artf',        # generic artifact\n",
        "    'eyem',        # eye movement / blink\n",
        "    'chew',        # chewing\n",
        "    'shiv',        # shiver / tremor\n",
        "    'musc',        # muscle artifact\n",
        "    'elec',        # electrode pop / line noise\n",
        "    # common multi-label combos found in TUSZ maps:\n",
        "    'eyem_chew','eyem_shiv','eyem_musc','eyem_elec',\n",
        "    'chew_shiv','chew_musc','chew_elec',\n",
        "    'shiv_musc','shiv_elec',\n",
        "    'musc_elec'\n",
        "}\n",
        "\n",
        "print(\"ROOT_DIR:\", ROOT_DIR)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering / resampling / normalization helpers\n",
        "\n",
        "### Bandpass 0.5–40 Hz (Kaiser FIR)\n",
        "- We design a linear-phase FIR using `firwin(..., window=('kaiser', beta))`.\n",
        "- We run `filtfilt` per channel to get zero-phase.\n",
        "- `filtfilt` needs enough padding, so we skip recordings that are too short.\n",
        "\n",
        "### Resampling\n",
        "- If original fs > 250 Hz, downsample to 250 using polyphase (`resample_poly`).\n",
        "- If fs <= 250 Hz, leave it (no upsampling).\n",
        "\n",
        "### Robust z-score\n",
        "- Per channel: subtract median, divide by IQR.\n",
        "- Flat channels (IQR ≈ 0) become ~0, which is fine."
      ],
      "metadata": {
        "id": "Gpgampe5fY7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _kaiser_beta_from_ripple(ripple_db: float) -> float:\n",
        "    \"\"\"\n",
        "    Approximate Kaiser beta as a function of desired stopband attenuation in dB.\n",
        "    \"\"\"\n",
        "    A = ripple_db\n",
        "    if A > 50:\n",
        "        return 0.1102 * (A - 8.7)\n",
        "    elif A >= 21:\n",
        "        return 0.5842 * (A - 21)**0.4 + 0.07886 * (A - 21)\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def apply_kaiser_bandpass(data, fs_orig, f_lo=0.5, f_hi=40.0, num_taps=101, ripple_db=60.0):\n",
        "\n",
        "    n_ch, n_samp = data.shape\n",
        "    padlen_needed = 3 * (num_taps - 1)\n",
        "    if n_samp <= padlen_needed:\n",
        "        raise ValueError(\n",
        "            f\"too short for filtfilt len={n_samp} need>{padlen_needed}\"\n",
        "        )\n",
        "\n",
        "    beta = _kaiser_beta_from_ripple(ripple_db)\n",
        "    taps = firwin(\n",
        "        numtaps=num_taps,\n",
        "        cutoff=[f_lo, f_hi],\n",
        "        pass_zero=False,\n",
        "        window=(\"kaiser\", beta),\n",
        "        fs=fs_orig,\n",
        "        scale=True,\n",
        "    )\n",
        "\n",
        "    # zero-phase per channel\n",
        "    filtered = np.stack([filtfilt(taps, [1.0], ch, axis=0) for ch in data], axis=0)\n",
        "    return filtered\n",
        "\n",
        "def maybe_resample_to_250(data, fs_orig, target_fs=TARGET_FS):\n",
        "\n",
        "    if abs(fs_orig - target_fs) < 1e-6:\n",
        "        return data, fs_orig\n",
        "    if fs_orig < target_fs:\n",
        "        print(f\"[WARN] fs {fs_orig} Hz < {target_fs} Hz, not upsampling.\")\n",
        "        return data, fs_orig\n",
        "\n",
        "    # integer ratio for resample_poly\n",
        "    from math import gcd\n",
        "    up = int(target_fs * 1000)\n",
        "    down = int(fs_orig * 1000)\n",
        "    g = gcd(up, down)\n",
        "    up //= g\n",
        "    down //= g\n",
        "\n",
        "    resampled = []\n",
        "    for ch in data:\n",
        "        ch_rs = resample_poly(ch, up, down)\n",
        "        resampled.append(ch_rs)\n",
        "    resampled = np.stack(resampled, axis=0)\n",
        "    return resampled, target_fs\n",
        "\n",
        "def robust_zscore(x, axis=1, eps_floor=1e-6, std_frac=0.1):\n",
        "\n",
        "    med = np.median(x, axis=axis, keepdims=True)\n",
        "    q1  = np.percentile(x, 25, axis=axis, keepdims=True)\n",
        "    q3  = np.percentile(x, 75, axis=axis, keepdims=True)\n",
        "    iqr = (q3 - q1)\n",
        "    std = np.std(x, axis=axis, keepdims=True)\n",
        "    denom = np.maximum(iqr, std_frac * std)\n",
        "    denom = np.maximum(denom, eps_floor)\n",
        "    return (x - med) / denom\n"
      ],
      "metadata": {
        "id": "YgYokb3Vf6Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotation loader (CSV)\n",
        "\n",
        "TUSZ seizure annotations are in `.csv` alongside the EDF. We:\n",
        "1. Open the `.csv` and try to locate the header line that contains `start` and `stop`.\n",
        "2. Read from that line forward using pandas.\n",
        "3. Extract time intervals for any label in a target label set.\n",
        "\n",
        "We create two label sets:\n",
        "- `SEIZURE_LABELS`: all events we consider “seizure” for model supervision.\n",
        "- `ARTIFACT_LABELS`: all events we consider “artifact / unusable background”, including muscle noise, eye movement, chewing, electrode pops, etc.\n",
        "\n",
        "We then define:\n",
        "- `load_seizure_intervals(csv_path)` → merged `(start_sec, stop_sec)` intervals containing seizure activity.\n",
        "- `load_artifact_intervals(csv_path)` → merged `(start_sec, stop_sec)` intervals containing artifact.\n",
        "\n",
        "Merging step:\n",
        "- If two intervals overlap or touch, we merge them into a single continuous interval.  \n",
        "  This prevents double-counting when annotations are dense.\n",
        "\n",
        "\n",
        "These intervals are later used to decide if each 10 s window is seizure, clean background, or should be thrown away due to artifact.\n"
      ],
      "metadata": {
        "id": "l8ulnVCZgCFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse_annotation_csv(csv_path: Path):\n",
        "\n",
        "    csv_path = Path(csv_path)\n",
        "    try:\n",
        "        raw_text = csv_path.read_text(errors=\"replace\")\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Could not open {csv_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    lines = raw_text.splitlines()\n",
        "    header_idx = None\n",
        "    for i, line in enumerate(lines):\n",
        "        low = line.lower()\n",
        "        if (\"start\" in low) and (\"stop\" in low):\n",
        "            header_idx = i\n",
        "            break\n",
        "\n",
        "    if header_idx is None:\n",
        "        # try naive pandas read\n",
        "        try:\n",
        "            ann = pd.read_csv(\n",
        "                csv_path,\n",
        "                sep=\",\",\n",
        "                engine=\"python\",\n",
        "                on_bad_lines=\"skip\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Could not parse {csv_path}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        main_body = \"\\n\".join(lines[header_idx:])\n",
        "        try:\n",
        "            ann = pd.read_csv(\n",
        "                io.StringIO(main_body),\n",
        "                sep=\",\",\n",
        "                engine=\"python\",\n",
        "                on_bad_lines=\"skip\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"WARNING: Could not smart-parse {csv_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    if ann is None or ann.empty:\n",
        "        return None\n",
        "\n",
        "    # normalize column names\n",
        "    ann.columns = [c.strip().lower() for c in ann.columns]\n",
        "    return ann\n",
        "\n",
        "\n",
        "def _extract_intervals_from_ann_df(ann_df: pd.DataFrame,\n",
        "                                   target_label_set: set[str]):\n",
        "\n",
        "    if ann_df is None or ann_df.empty:\n",
        "        return []\n",
        "\n",
        "    # figure out column names for start/stop and label\n",
        "    if 'start_time' in ann_df.columns:\n",
        "        start_col = 'start_time'\n",
        "    elif 'start' in ann_df.columns:\n",
        "        start_col = 'start'\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "    if 'stop_time' in ann_df.columns:\n",
        "        stop_col = 'stop_time'\n",
        "    elif 'stop' in ann_df.columns:\n",
        "        stop_col = 'stop'\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "    if 'label' in ann_df.columns:\n",
        "        label_col = 'label'\n",
        "    elif 'type' in ann_df.columns:\n",
        "        label_col = 'type'\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "    # normalize the label column\n",
        "    tmp = ann_df.copy()\n",
        "    tmp[label_col] = tmp[label_col].astype(str).str.lower().str.strip()\n",
        "\n",
        "    use_rows = tmp[tmp[label_col].isin(target_label_set)]\n",
        "    if use_rows.empty:\n",
        "        return []\n",
        "\n",
        "    raw_intervals = []\n",
        "    for _, r in use_rows.iterrows():\n",
        "        try:\n",
        "            s = float(r[start_col])\n",
        "            e = float(r[stop_col])\n",
        "        except Exception:\n",
        "            continue\n",
        "        if not np.isfinite(s) or not np.isfinite(e):\n",
        "            continue\n",
        "        if e <= s:\n",
        "            continue\n",
        "        raw_intervals.append([s, e])\n",
        "\n",
        "    if not raw_intervals:\n",
        "        return []\n",
        "\n",
        "    # merge overlaps\n",
        "    raw_intervals.sort(key=lambda x: x[0])\n",
        "    merged = [raw_intervals[0]]\n",
        "    for s, e in raw_intervals[1:]:\n",
        "        ls, le = merged[-1]\n",
        "        if s <= le:\n",
        "            merged[-1][1] = max(le, e)\n",
        "        else:\n",
        "            merged.append([s, e])\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "def load_seizure_intervals(csv_path: Path):\n",
        "    ann_df = _parse_annotation_csv(csv_path)\n",
        "    return _extract_intervals_from_ann_df(ann_df, SEIZURE_LABELS)\n",
        "\n",
        "\n",
        "def load_artifact_intervals(csv_path: Path):\n",
        "    ann_df = _parse_annotation_csv(csv_path)\n",
        "    return _extract_intervals_from_ann_df(ann_df, ARTIFACT_LABELS)\n"
      ],
      "metadata": {
        "id": "ccDrdpazgG9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sliding window extraction and labeling\n",
        "\n",
        "We cut the filtered, resampled, z-scored EEG into 10 s windows with 5 s hop.\n",
        "\n",
        "For each window `[w_start, w_end]`:\n",
        "1. We label windows for **prediction** as follows, per annotated seizure `(onset, offset)`:\n",
        "\n",
        "- **y = 1 (pre-ictal)**: `[onset − SOP_MIN, onset − SPH_MIN]`\n",
        "- **ignored (SPH)**: `(onset − SPH_MIN, onset)`\n",
        "- **y = 0 (early-ictal)**: `[onset, min(onset + EARLY_ICTAL_KEPT_S, offset)]`\n",
        "- **ignored (rest ictal)**: `(onset + EARLY_ICTAL_KEPT_S, offset]`\n",
        "- **ignored (post-ictal optional)**: `(offset, offset + POSTICTAL_BUFFER_S]` if `POSTICTAL_BUFFER_S > 0`\n",
        "\n",
        "Artifact rule: windows overlapping artifact intervals are dropped, except pre-ictal windows may be kept if `KEEP_PREICTAL_EVEN_IF_ARTIFACT = True`.\n",
        "\n",
        "We return:\n",
        "- `X_arr`: `[N_win, C, T]`\n",
        "- `y_arr`: `[N_win]` seizure/background labels\n",
        "- `t0_arr`: `[N_win]` start time (sec from file start)\n"
      ],
      "metadata": {
        "id": "yZ_JVhxegKSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data_with_artifact(data,\n",
        "                              fs,\n",
        "                              seizure_intervals,\n",
        "                              artifact_intervals,\n",
        "                              win_len_s,\n",
        "                              hop_s):\n",
        "    def _merge(iv):\n",
        "        if not iv:\n",
        "            return []\n",
        "        iv = sorted(iv, key=lambda x: x[0])\n",
        "        out = [iv[0]]\n",
        "        for s, e in iv[1:]:\n",
        "            ls, le = out[-1]\n",
        "            if s <= le:\n",
        "                out[-1][1] = max(le, e)\n",
        "            else:\n",
        "                out.append([s, e])\n",
        "        return [(s, e) for s, e in out]\n",
        "\n",
        "\n",
        "    def _regions_prediction(seiz_iv, sop_s, sph_s, early_s, post_s):\n",
        "        \"\"\"\n",
        "        Build regions per seizure:\n",
        "        pre  -> y=1 (pre-ictal): [onset - SOP, onset - SPH]\n",
        "        igp  -> ignore: (onset - SPH, onset)\n",
        "        e0   -> y=0: early ictal [onset, onset + early_s]\n",
        "        igi  -> ignore: rest ictal\n",
        "        igpo -> ignore: optional post-ictal buffer\n",
        "        \"\"\"\n",
        "        pre, igp, e0, igi, igpo = [], [], [], [], []\n",
        "        for on, off in seiz_iv:\n",
        "            if off <= on:\n",
        "                continue\n",
        "            pre.append((max(0.0, on - sop_s), max(0.0, on - sph_s)))\n",
        "            igp.append((max(0.0, on - sph_s), on))\n",
        "            ei = min(on + early_s, off)\n",
        "            if ei > on:\n",
        "                e0.append((on, ei))\n",
        "            if off > ei:\n",
        "                igi.append((ei, off))\n",
        "            if post_s > 0:\n",
        "                igpo.append((off, off + post_s))\n",
        "        return {\n",
        "            \"pre\":  _merge([x for x in pre  if x[1] > x[0]]),\n",
        "            \"igp\":  _merge([x for x in igp  if x[1] > x[0]]),\n",
        "            \"e0\":   _merge([x for x in e0   if x[1] > x[0]]),\n",
        "            \"igi\":  _merge([x for x in igi  if x[1] > x[0]]),\n",
        "            \"igpo\": _merge([x for x in igpo if x[1] > x[0]]),\n",
        "        }\n",
        "\n",
        "\n",
        "    def _overlaps(w, ivs):\n",
        "        ws, we = w\n",
        "        for s, e in ivs:\n",
        "            if ws < e and we > s:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def window_prediction_with_artifacts(data, fs, seizure_iv, artifact_iv,\n",
        "                                         win_s, hop_s,\n",
        "                                         sop_s, sph_s, early_s, post_s,\n",
        "                                         keep_pre_artf=True):\n",
        "        \"\"\"\n",
        "        Prediction labels only (minimal change):\n",
        "        - y=1 for pre-ictal windows in [onset - SOP, onset - SPH]\n",
        "        - y=0 for interictal and EARLY ictal [onset, onset + early_s]\n",
        "        - ignore SPH band, the rest of ictal, and optional post-ictal\n",
        "        - drop artifact-overlapping windows, except keep pre-ictal if keep_pre_artf=True\n",
        "        \"\"\"\n",
        "        regs = _regions_prediction(seizure_iv, sop_s, sph_s, early_s, post_s)\n",
        "        pre, igp, e0, igi, igpo = regs[\"pre\"], regs[\"igp\"], regs[\"e0\"], regs[\"igi\"], regs[\"igpo\"]\n",
        "\n",
        "        C, N = data.shape\n",
        "        W = int(round(win_s * fs))\n",
        "        H = int(round(hop_s * fs))\n",
        "        Xs, Ys, T0 = [], [], []\n",
        "        drop_a = drop_i = 0\n",
        "\n",
        "        i = 0\n",
        "        while i + W <= N:\n",
        "            seg = data[:, i:i+W]\n",
        "            ws, we = i / fs, (i + W) / fs\n",
        "            w = (ws, we)\n",
        "\n",
        "            # ignore zones (prediction horizon, rest ictal, post-ictal)\n",
        "            if _overlaps(w, igp) or _overlaps(w, igi) or _overlaps(w, igpo):\n",
        "                drop_i += 1\n",
        "                i += H\n",
        "                continue\n",
        "\n",
        "            # positive: pre-ictal\n",
        "            if _overlaps(w, pre):\n",
        "                if (not keep_pre_artf) and _overlaps(w, artifact_iv):\n",
        "                    drop_a += 1\n",
        "                    i += H\n",
        "                    continue\n",
        "                Xs.append(seg); Ys.append(1); T0.append(ws)\n",
        "                i += H\n",
        "                continue\n",
        "\n",
        "            # negative: early ictal\n",
        "            if _overlaps(w, e0):\n",
        "                if _overlaps(w, artifact_iv):\n",
        "                    drop_a += 1\n",
        "                    i += H\n",
        "                    continue\n",
        "                Xs.append(seg); Ys.append(0); T0.append(ws)\n",
        "                i += H\n",
        "                continue\n",
        "\n",
        "            # interictal negative (unless artifact)\n",
        "            if _overlaps(w, artifact_iv):\n",
        "                drop_a += 1\n",
        "                i += H\n",
        "                continue\n",
        "\n",
        "            Xs.append(seg); Ys.append(0); T0.append(ws)\n",
        "            i += H\n",
        "\n",
        "        if not Xs:\n",
        "            return (np.empty((0, C, W), dtype=np.float32),\n",
        "                    np.empty((0,), dtype=np.int64),\n",
        "                    np.empty((0,), dtype=np.float32),\n",
        "                    drop_a, drop_i)\n",
        "\n",
        "        X = np.stack(Xs, axis=0).astype(np.float32)\n",
        "        y = np.array(Ys, dtype=np.int64)\n",
        "        t0 = np.array(T0, dtype=np.float32)\n",
        "        return X, y, t0, drop_a, drop_i\n",
        "\n",
        "    X, y, t0s, dropped_art, dropped_ignored = window_prediction_with_artifacts(\n",
        "        data, fs, seizure_intervals, artifact_intervals,\n",
        "        win_s=win_len_s,\n",
        "        hop_s=hop_s,\n",
        "        sop_s=SOP_MIN,\n",
        "        sph_s=SPH_MIN,\n",
        "        early_s=EARLY_ICTAL_KEPT_S,\n",
        "        post_s=POSTICTAL_BUFFER_S,\n",
        "        keep_pre_artf=KEEP_PREICTAL_EVEN_IF_ARTIFACT,\n",
        "    )\n",
        "    # Old code only tracked artifact drops; ignore-count is still logged upstream if you want.\n",
        "    return X, y, t0s, int(dropped_art)\n"
      ],
      "metadata": {
        "id": "TBZ6X-y3gOVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matching EDF ↔ CSV\n",
        "\n",
        "We try several strategies to find the annotation `.csv` that goes with an EDF:\n",
        "1. Exact stem match: `file.edf` → `file.csv`\n",
        "2. A `.csv` whose stem starts with the EDF stem\n",
        "3. If there's exactly one `.csv` in the folder, assume it's the match\n"
      ],
      "metadata": {
        "id": "qx68JrDmgRyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_annotation_for_edf(edf_path: Path):\n",
        "    edf_path = Path(edf_path)\n",
        "    d = edf_path.parent\n",
        "    stem = edf_path.stem\n",
        "\n",
        "    exact = d / f\"{stem}.csv\"\n",
        "    if exact.exists():\n",
        "        return exact\n",
        "\n",
        "    csvs = list(d.glob('*.csv'))\n",
        "    pref = [c for c in csvs if c.stem.startswith(stem)]\n",
        "    if pref:\n",
        "        return pref[0]\n",
        "\n",
        "    if len(csvs) == 1:\n",
        "        return csvs[0]\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "SLEZ7USTgVL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smart Canonical Montage: channel normalization + alignment\n",
        "\n",
        "### `_normalize_ch_name`\n",
        "We normalize channel names so variants like:\n",
        "- `EEG FP1-F7`\n",
        "- `fp1_f7-ref`\n",
        "- `FP1–F7`\n",
        "map to the same key: `FP1-F7`.\n",
        "This handles prefixes (`EEG `), suffixes (`-REF`, `-AVG`, etc.), underscores, fancy dashes.\n",
        "\n",
        "### `align_to_reference`\n",
        "For each processed recording *after* filtering/z-scoring/windowing:\n",
        "- We know its own channel names (`dbg['channel_names']`).\n",
        "- We know the **reference channel layout** picked from the *first* good recording `ref_ch_names`.\n",
        "- We build a lookup from normalized channel name → row index in this recording.\n",
        "- For each ref channel name, if we find a match, we copy that row; if not, we insert zeros.\n",
        "- We track coverage_ratio = fraction of ref channels we successfully filled.\n",
        "If coverage is too low (<30% by default), we skip that recording so we don't poison the dataset with mostly zeros.\n"
      ],
      "metadata": {
        "id": "fEFOwBF3gYJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _normalize_ch_name(name: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize a bipolar channel label so that variants like\n",
        "    'Fp1-F7', 'EEG FP1-F7', 'fp1_f7-ref', 'FP1–F7', 'FP1-F7-AVG'\n",
        "    all map to 'FP1-F7'.\n",
        "    We are **not** constructing new bipolar pairs here. We're just\n",
        "    making naming consistent so we can match channels across recordings.\n",
        "    \"\"\"\n",
        "    n = name.upper().strip()\n",
        "\n",
        "    # drop leading 'EEG '\n",
        "    n = re.sub(r'^EEG\\s+', '', n)\n",
        "\n",
        "    # normalize fancy dashes to plain '-'\n",
        "    n = n.replace('–', '-').replace('—', '-')\n",
        "\n",
        "    # collapse spaces/underscores into '-'\n",
        "    n = re.sub(r'[\\s_]+', '-', n)\n",
        "\n",
        "    # remove common reference suffixes like -REF, -AVG, -AV, -LE, A1/A2, M1/M2\n",
        "    n = re.sub(r'-(REF|AVG|AV|LE|A1|A2|M1|M2)$', '', n)\n",
        "\n",
        "    # collapse multiple dashes\n",
        "    n = re.sub(r'-+', '-', n)\n",
        "\n",
        "    # trim stray '-'\n",
        "    n = n.strip('- ')\n",
        "\n",
        "    return n\n",
        "\n",
        "def align_to_reference(data_curr, ch_names_curr, ref_ch_names):\n",
        "\n",
        "    norm_lookup = {}\n",
        "    for i, nm in enumerate(ch_names_curr):\n",
        "        norm_lookup[_normalize_ch_name(nm)] = i\n",
        "\n",
        "    T = data_curr.shape[1]\n",
        "    out = np.zeros((len(ref_ch_names), T), dtype=data_curr.dtype)\n",
        "\n",
        "    filled = 0\n",
        "    for i, ref_nm in enumerate(ref_ch_names):\n",
        "        idx = norm_lookup.get(_normalize_ch_name(ref_nm))\n",
        "        if idx is not None:\n",
        "            out[i, :] = data_curr[idx, :]\n",
        "            filled += 1\n",
        "\n",
        "    coverage_ratio = filled / max(1, len(ref_ch_names))\n",
        "    return out, coverage_ratio\n"
      ],
      "metadata": {
        "id": "OgKsPPIigcUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess a single EDF\n",
        "\n",
        "Steps:\n",
        "1. Load EDF with MNE.\n",
        "2. 0.5–40 Hz bandpass via Kaiser FIR + zero-phase `filtfilt`.\n",
        "3. Downsample to 250 Hz if fs > 250 (never upsample).\n",
        "4. Robust z-score per channel.\n",
        "5. Load seizure intervals from .csv, merge overlaps.\n",
        "6. Slice into 10s windows / 5s hop.\n",
        "7. Label seizure(1)/background(0).\n",
        "8. We call `window_data_with_artifact(...)`, which slides 10 s / 5 s hop windows across the normalized EEG and returns only the windows we want to train on.\n",
        "   - Rules:\n",
        "     - Overlap seizure: KEEP (label=1).\n",
        "     - Overlap artifact (but no seizure) → DROP.\n",
        "     - Otherwise: KEEP as background (label=0).\n",
        "   - We count:\n",
        "     - how many windows we kept,\n",
        "     - how many were labeled seizure vs background,\n",
        "     - how many artifact-only windows we dropped.\n",
        "\n",
        "Returns:\n",
        "- `X` shape `[N_win, C_curr, T]` in THE RECORDING'S OWN channel order (not aligned yet)\n",
        "- `y` shape `[N_win]`\n",
        "- `meta` dict with bookkeeping\n",
        "- `debug_preview` dict with windows, labels, fs, channel_names (used later for alignment & QC)\n"
      ],
      "metadata": {
        "id": "usslL05QggyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_single_recording_raw(\n",
        "    edf_path: Path,\n",
        "    ann_csv_path: Path,\n",
        "    win_len_s=WIN_LEN_S,\n",
        "    hop_s=HOP_S,\n",
        "    num_taps=NUM_TAPS\n",
        "):\n",
        "\n",
        "    print(f\"INFO ONLY: EDF: {edf_path.as_posix()}\")\n",
        "    print(f\"       CSV: {ann_csv_path.as_posix()}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Load raw EDF with MNE\n",
        "    # -------------------------------------------------\n",
        "    raw = mne.io.read_raw_edf(\n",
        "        edf_path.as_posix(),\n",
        "        preload=True,\n",
        "        verbose='ERROR'\n",
        "    )\n",
        "\n",
        "    data = raw.get_data()      # shape [C_raw, N_samples]\n",
        "    ch_names = raw.ch_names    # list of length C_raw\n",
        "    fs_orig = float(raw.info['sfreq'])\n",
        "    n_samp = data.shape[1]\n",
        "\n",
        "    print(f\"       fs_orig={fs_orig} Hz  ch={data.shape[0]}  n_samples={n_samp}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Check if clip is long enough for filtfilt padding\n",
        "    # filtfilt needs ~3*(num_taps-1) samples of margin.\n",
        "    # If not long enough, we cannot safely apply the Kaiser filter.\n",
        "    # We just skip this recording entirely.\n",
        "    # -------------------------------------------------\n",
        "    padlen_needed = 3 * (num_taps - 1)\n",
        "    if n_samp <= padlen_needed:\n",
        "        print(f\"       [SKIP SHORT] len={n_samp/fs_orig:.1f}s \"\n",
        "              f\"(need >{padlen_needed/fs_orig:.1f}s for filtfilt with {num_taps} taps)\")\n",
        "        return (\n",
        "            np.empty((0,0,0), dtype=np.float32),\n",
        "            np.empty((0,), dtype=np.int64),\n",
        "            {\n",
        "                'recording_id': edf_path.stem,\n",
        "                'fs': fs_orig,\n",
        "                'skipped_short': True,\n",
        "                'num_windows': 0,\n",
        "                'num_Pre_Ictal_windows': 0,\n",
        "                'num_Negative_windows': 0,\n",
        "                'num_artifact_windows_dropped': 0,\n",
        "                'total_seizure_seconds_in_file': 0.0,\n",
        "                'total_artifact_seconds_in_file': 0.0,\n",
        "                'raw_ch_names': ch_names,\n",
        "                'num_channels_raw': len(ch_names),\n",
        "            },\n",
        "            None,\n",
        "        )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 0.5–40 Hz bandpass using Kaiser FIR with zero-phase filtfilt\n",
        "    # -------------------------------------------------\n",
        "    data_bp = apply_kaiser_bandpass(\n",
        "        data,\n",
        "        fs_orig,\n",
        "        f_lo=0.5,\n",
        "        f_hi=40.0,\n",
        "        num_taps=num_taps,\n",
        "        ripple_db=60.0,\n",
        "    )\n",
        "    print(f\"       after bandpass: {data_bp.shape}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Downsample if needed\n",
        "    # If fs_orig > TARGET_FS (e.g. 500 Hz), we polyphase resample down to 250 Hz\n",
        "    # for anti-aliasing + speed.\n",
        "    # If fs_orig <= TARGET_FS, we keep as is (no upsampling).\n",
        "    # -------------------------------------------------\n",
        "    data_ds, fs_proc = maybe_resample_to_250(\n",
        "        data_bp,\n",
        "        fs_orig,\n",
        "        target_fs=TARGET_FS\n",
        "    )\n",
        "    print(f\"       after resample check: {data_ds.shape}, fs_proc={fs_proc}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Robust z-score (median / IQR) per channel\n",
        "    # -------------------------------------------------\n",
        "    data_norm = robust_zscore(data_ds)\n",
        "    print(f\"       after robust z-score: {data_norm.shape}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Load seizure + artifact intervals from CSV\n",
        "    # We will use both to decide which windows to keep.\n",
        "    # - seizure windows: always kept, labeled 1\n",
        "    # - artifact-only windows: dropped entirely\n",
        "    # - clean windows: kept, labeled 0\n",
        "    # -------------------------------------------------\n",
        "    seizure_intervals = load_seizure_intervals(ann_csv_path)\n",
        "    artifact_intervals = load_artifact_intervals(ann_csv_path)\n",
        "\n",
        "    total_sz_sec = (\n",
        "        sum(e - s for (s, e) in seizure_intervals)\n",
        "        if seizure_intervals else 0.0\n",
        "    )\n",
        "    total_artf_sec = (\n",
        "        sum(e - s for (s, e) in artifact_intervals)\n",
        "        if artifact_intervals else 0.0\n",
        "    )\n",
        "\n",
        "    print(f\"       seizure_intervals={seizure_intervals}\")\n",
        "    print(f\"       total seizure sec in file: {total_sz_sec:.2f}\")\n",
        "    print(f\"       artifact_intervals={artifact_intervals}\")\n",
        "    print(f\"       total artifact sec in file: {total_artf_sec:.2f}\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Sliding windows with artifact-aware policy\n",
        "    # window_data_with_artifact() returns:\n",
        "    #   X  -> kept windows [N_keep, C_curr, T]\n",
        "    #   y  -> labels [N_keep] (1=seizure, 0=clean background)\n",
        "    #   t0s -> start times of windows (sec from start)\n",
        "    #   dropped_art -> how many windows we removed due to artifact-only contamination\n",
        "    # -------------------------------------------------\n",
        "    X, y, t0s, dropped_art = window_data_with_artifact(\n",
        "        data_norm,\n",
        "        fs_proc,\n",
        "        seizure_intervals,\n",
        "        artifact_intervals,\n",
        "        win_len_s=win_len_s,\n",
        "        hop_s=hop_s,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"       => {X.shape[0]} KEPT windows | \"\n",
        "        f\"PI={int(np.sum(y==1))} | \"\n",
        "        f\"Ng={int(np.sum(y==0))} | \"\n",
        "        f\"dropped_artifact={dropped_art}\"\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Build debug_preview for downstream reference alignment and QC plotting.\n",
        "    # NOTE: channel_names here are the ORIGINAL channel order for THIS EDF.\n",
        "    # We'll align them to the canonical montage later in build_split().\n",
        "    # -------------------------------------------------\n",
        "    debug_preview = None\n",
        "    if X.shape[0] > 0:\n",
        "        debug_preview = {\n",
        "            'recording_id': edf_path.stem,\n",
        "            'all_windows': X,        # [N_keep, C_curr, T]\n",
        "            'all_labels': y,         # [N_keep]\n",
        "            'fs': fs_proc,\n",
        "            'channel_names': ch_names,\n",
        "        }\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # Metadata for analysis and auditing\n",
        "    # We'll also store:\n",
        "    #   - total_artifact_seconds_in_file\n",
        "    #   - num_artifact_windows_dropped\n",
        "    # -------------------------------------------------\n",
        "    meta = {\n",
        "        'recording_id': edf_path.stem,\n",
        "        'fs': fs_proc,\n",
        "        'num_windows': int(len(y)),\n",
        "        'num_Pre_Ictal_windows': int(np.sum(y==1)),\n",
        "        'num_Negative_windows': int(np.sum(y==0)),\n",
        "        'num_artifact_windows_dropped': int(dropped_art),\n",
        "        'total_seizure_seconds_in_file': total_sz_sec,\n",
        "        'total_artifact_seconds_in_file': total_artf_sec,\n",
        "        'skipped_short': False,\n",
        "        'raw_ch_names': ch_names,\n",
        "        'num_channels_raw': data_norm.shape[0],\n",
        "    }\n",
        "\n",
        "    return X, y, meta, debug_preview"
      ],
      "metadata": {
        "id": "ERa6CQb4gjm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build a split (`train`, `dev`, or `eval`)\n",
        "\n",
        "Algorithm:\n",
        "1. Collect all EDF files under the chosen split dir.\n",
        "2. If `GROUP_MODE == 'subject'`, group EDFs by subject folder and cap at `MAX_SUBJECTS`.\n",
        "3. For each EDF:\n",
        "   - Preprocess.\n",
        "   - The first usable recording defines `ref_ch_names` (our learned canonical montage order).\n",
        "   - For each window in that recording (and all later recordings), align channel order to `ref_ch_names` using `align_to_reference`.\n",
        "   - Compute coverage_ratio for that recording (fraction of ref channels actually present).\n",
        "   - If coverage_ratio < `min_coverage` (default 0.3 = 30%), skip that recording so we don't add mostly-zero tensors.\n",
        "4. Concatenate aligned windows across recordings -> one big `X_split`, `y_split`.\n",
        "5. Pick the best debug candidate for QC plotting (prefer seizure-heavy recording).\n"
      ],
      "metadata": {
        "id": "nYdeD9wWgmTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _extract_subject_id(split_root: Path, edf_path: Path) -> str:\n",
        "    rel = edf_path.relative_to(split_root)\n",
        "    parts = rel.parts\n",
        "    if len(parts) < 2:\n",
        "        return \"unknown\"\n",
        "    return parts[0]\n",
        "\n",
        "def build_split(split_root: Path,\n",
        "                group_mode=GROUP_MODE,\n",
        "                max_subjects=MAX_SUBJECTS,\n",
        "                max_recordings=MAX_RECORDINGS,\n",
        "                win_len_s=WIN_LEN_S,\n",
        "                hop_s=HOP_S,\n",
        "                num_taps=NUM_TAPS,\n",
        "                min_coverage=0.3):\n",
        "    \"\"\"\n",
        "    min_coverage:\n",
        "      If a recording can't map at least this fraction of the reference channels,\n",
        "      we skip it (to avoid mostly-zero data).\n",
        "    \"\"\"\n",
        "\n",
        "    split_root = Path(split_root)\n",
        "    print(f\"\\n INFO ONLY ==== Processing split: {split_root.as_posix()} ====\")\n",
        "\n",
        "    edf_files = list(split_root.rglob(\"*.edf\"))\n",
        "    print(f\"INFO ONLY: Found {len(edf_files)} EDF files under {split_root.as_posix()}\")\n",
        "\n",
        "    X_all_list = []\n",
        "    y_all_list = []\n",
        "    metas = []\n",
        "    debug_candidates = []\n",
        "\n",
        "    ref_ch_names = None  # learned canonical order from the first usable recording\n",
        "\n",
        "    def handle_edf_list(edf_iter):\n",
        "        nonlocal ref_ch_names\n",
        "        count_used = 0\n",
        "        for edf_path in edf_iter:\n",
        "            if max_recordings is not None and count_used >= max_recordings:\n",
        "                break\n",
        "\n",
        "            ann_path = find_best_annotation_for_edf(edf_path)\n",
        "            if ann_path is None:\n",
        "                print(\"[SKIP NO CSV]\", edf_path.as_posix(),\n",
        "                      \"CSV candidates:\", [c.name for c in edf_path.parent.glob(\"*.csv\")])\n",
        "                continue\n",
        "\n",
        "            X_rec, y_rec, meta_rec, dbg = preprocess_single_recording_raw(\n",
        "                edf_path,\n",
        "                ann_path,\n",
        "                win_len_s=win_len_s,\n",
        "                hop_s=hop_s,\n",
        "                num_taps=num_taps,\n",
        "            )\n",
        "\n",
        "            if X_rec.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            # first usable recording defines reference channel layout\n",
        "            if ref_ch_names is None:\n",
        "                if dbg is None:\n",
        "                    continue\n",
        "                ref_ch_names = list(dbg['channel_names'])\n",
        "                print(f\"INFO ONLY: reference channel layout set from {edf_path.stem}:\")\n",
        "                print(ref_ch_names)\n",
        "\n",
        "            # align every window in this recording to ref_ch_names\n",
        "            aligned_list = []\n",
        "            coverages = []\n",
        "            for w in X_rec:  # w: [C_curr, T]\n",
        "                aligned_w, cov = align_to_reference(\n",
        "                    w,\n",
        "                    dbg['channel_names'],\n",
        "                    ref_ch_names\n",
        "                )\n",
        "                aligned_list.append(aligned_w)\n",
        "                coverages.append(cov)\n",
        "\n",
        "            X_rec_aligned = np.stack(aligned_list, axis=0).astype(np.float32)\n",
        "            avg_cov = float(np.mean(coverages)) if len(coverages) else 0.0\n",
        "            print(f\"       coverage for {edf_path.stem}: {avg_cov*100:.1f}%\")\n",
        "\n",
        "            # skip low-coverage recordings (prevents mostly-zero tensors)\n",
        "            if avg_cov < min_coverage:\n",
        "                print(f\"       SKIP LOW COVERAGE {edf_path.stem} \"\n",
        "                      f\"({avg_cov*100:.1f}% < {min_coverage*100:.1f}%)\")\n",
        "                continue\n",
        "\n",
        "            # keep it\n",
        "            X_all_list.append(X_rec_aligned)\n",
        "            y_all_list.append(y_rec)\n",
        "\n",
        "            meta_with_cov = dict(meta_rec)\n",
        "            meta_with_cov['coverage_ratio'] = avg_cov\n",
        "            metas.append(meta_with_cov)\n",
        "            count_used += 1\n",
        "\n",
        "            # candidate for QC plotting\n",
        "            if dbg is not None:\n",
        "                debug_candidates.append({\n",
        "                    'recording_id': dbg['recording_id'],\n",
        "                    'all_windows': X_rec_aligned,\n",
        "                    'all_labels': y_rec,\n",
        "                    'fs': dbg['fs'],\n",
        "                    'channel_names': ref_ch_names,\n",
        "                })\n",
        "\n",
        "    if group_mode == \"recording\":\n",
        "        handle_edf_list(edf_files)\n",
        "    else:\n",
        "        subj_to_edfs = {}\n",
        "        for edf_path in edf_files:\n",
        "            subj_id = _extract_subject_id(split_root, edf_path)\n",
        "            subj_to_edfs.setdefault(subj_id, []).append(edf_path)\n",
        "\n",
        "        subjects_sorted = sorted(subj_to_edfs.keys())[:max_subjects]\n",
        "        print(f\"[INFO] Subjects used (cap={max_subjects}): {subjects_sorted}\")\n",
        "\n",
        "        for subj_id in subjects_sorted:\n",
        "            recs_this_subj = subj_to_edfs[subj_id]\n",
        "            handle_edf_list(recs_this_subj)\n",
        "\n",
        "    # concatenate aligned windows from all accepted recordings\n",
        "    if len(X_all_list) == 0:\n",
        "        X_all = np.empty((0,0,0), dtype=np.float32)\n",
        "        y_all = np.empty((0,), dtype=np.int64)\n",
        "    else:\n",
        "        X_all = np.concatenate(X_all_list, axis=0)\n",
        "        y_all = np.concatenate(y_all_list, axis=0)\n",
        "\n",
        "    # pick best debug candidate for QC plotting (prefer more seizure windows)\n",
        "    best_dbg = None\n",
        "    best_sz = -1\n",
        "    best_total = -1\n",
        "    for dbg in debug_candidates:\n",
        "        labels = dbg.get('all_labels', None)\n",
        "        wins   = dbg.get('all_windows', None)\n",
        "        if labels is None or wins is None:\n",
        "            continue\n",
        "\n",
        "        sz_count = int(np.sum(labels == 1))\n",
        "        total_w  = int(len(labels))\n",
        "        if sz_count > best_sz:\n",
        "            best_dbg = dbg\n",
        "            best_sz = sz_count\n",
        "            best_total = total_w\n",
        "        elif sz_count == best_sz and total_w > best_total:\n",
        "            best_dbg = dbg\n",
        "            best_total = total_w\n",
        "\n",
        "    return X_all, y_all, metas, best_dbg\n"
      ],
      "metadata": {
        "id": "-3ZNxpNvgpg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run preprocessing for one split\n",
        "\n",
        "Set `SPLIT` to `'train'`, `'dev'`, or `'eval'`.\n",
        "This cell will:\n",
        "1. Call `build_split`.\n",
        "2. Print dataset stats and class balance.\n",
        "3. Report the debug candidate we'll use for QC plotting.\n"
      ],
      "metadata": {
        "id": "uIJB4V9PgsiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT = \"train\"  # change to \"dev\" or \"eval\" as needed\n",
        "\n",
        "split_dir = ROOT_DIR / SPLIT\n",
        "X_split, y_split, meta_split, dbg_split = build_split(\n",
        "    split_dir,\n",
        "    group_mode=GROUP_MODE,\n",
        "    max_subjects=MAX_SUBJECTS,\n",
        "    max_recordings=MAX_RECORDINGS,\n",
        "    win_len_s=WIN_LEN_S,\n",
        "    hop_s=HOP_S,\n",
        "    num_taps=NUM_TAPS,\n",
        "    min_coverage=0.3,  # skip recordings with <30% channel match\n",
        ")\n",
        "\n",
        "print(\"\\n=== SPLIT SUMMARY ===\")\n",
        "print(\"X_split shape:\", getattr(X_split, 'shape', None))\n",
        "print(\"y_split shape:\", getattr(y_split, 'shape', None))\n",
        "\n",
        "total_windows = len(y_split)\n",
        "num_bg = int(np.sum(y_split == 0)) if total_windows > 0 else 0\n",
        "num_sz = int(np.sum(y_split == 1)) if total_windows > 0 else 0\n",
        "pct_bg = (100.0 * num_bg / total_windows) if total_windows > 0 else 0.0\n",
        "pct_sz = (100.0 * num_sz / total_windows) if total_windows > 0 else 0.0\n",
        "\n",
        "print(f\"Total windows: {total_windows}\")\n",
        "print(f\"Negative windows: {num_bg} ({pct_bg:.2f}%)\")\n",
        "print(f\"Pre Ictal windows:    {num_sz} ({pct_sz:.2f}%)\")\n",
        "print(f\"Class ratio (bg : sz) ~ {num_bg}:{num_sz}\")\n",
        "\n",
        "if dbg_split is not None:\n",
        "    lbls_dbg = dbg_split.get('all_labels', None)\n",
        "    if lbls_dbg is not None:\n",
        "        print(\"Best debug recording:\", dbg_split.get('recording_id','n/a'))\n",
        "        print(\"Pre Ictal windows in debug rec:\", int(np.sum(lbls_dbg==1)))\n",
        "else:\n",
        "    print('WARNING: No debug candidate available to plot.')\n"
      ],
      "metadata": {
        "id": "vEN1_zs8gvBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QC plot\n",
        "\n",
        "We pick an informative EEG window from `dbg_split`:\n",
        "1. Prefer seizure windows first (label==1), otherwise background.\n",
        "2. Within that window, pick the channel with the highest std (so we avoid flat zero-fill rows).\n",
        "3. Plot that channel's robust z-scored signal.\n",
        "We save this as `qc_window.png` in `OUT_DIR`.\n",
        "\n",
        "**Note:** Pre-ictal positives (y=1) are quieter than ictal by design; class balance may be skewed if `SOP_MIN` is small or `SPH_MIN` is large. QC plots use safe robust z-score (denominator clamped by `max(IQR, 0.1*STD, 1e-6)`) to avoid extreme amplitudes on very low-variance channels.\n",
        "\n"
      ],
      "metadata": {
        "id": "J8FARcsKg0aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_informative_window(dbg_dict, motion_thresh=1e-6, iqr_eps=1e-6):\n",
        "    if dbg_dict is None: return None, None\n",
        "    X_all = dbg_dict.get('all_windows'); y_all = dbg_dict.get('all_labels')\n",
        "    if X_all is None or y_all is None or len(y_all) == 0: return None, None\n",
        "\n",
        "    # prefer positives\n",
        "    idx_pos = np.where(y_all == 1)[0]; idx_neg = np.where(y_all == 0)[0]\n",
        "    for w_i in list(idx_pos) + list(idx_neg):\n",
        "        W = X_all[w_i]  # [C,T]\n",
        "        ch_std = np.std(W, axis=1)\n",
        "        q25 = np.percentile(W, 25, axis=1); q75 = np.percentile(W, 75, axis=1)\n",
        "        ch_iqr = q75 - q25\n",
        "        ok = np.where((ch_std > motion_thresh) & (ch_iqr > iqr_eps))[0]\n",
        "        if ok.size:\n",
        "            ch_i = int(ok[np.argmax(ch_std[ok])])\n",
        "            return w_i, ch_i\n",
        "    return None, None\n",
        "\n",
        "if dbg_split is not None:\n",
        "    w_i, ch_i = pick_informative_window(dbg_split, motion_thresh=1e-6, iqr_eps=1e-6)\n",
        "    if w_i is not None:\n",
        "        X_all = dbg_split['all_windows']; y_all = dbg_split['all_labels']; fs_dbg = float(dbg_split['fs'])\n",
        "        sig = X_all[w_i, ch_i, :].astype(float); label_dbg = int(y_all[w_i])\n",
        "        t_axis = np.arange(sig.shape[0]) / fs_dbg\n",
        "\n",
        "        # re-normalize just for the figure so axes are sane\n",
        "        med = np.median(sig)\n",
        "        iqr = np.percentile(sig, 75) - np.percentile(sig, 25)\n",
        "        std = np.std(sig)\n",
        "        denom = max(iqr, 0.1*std, 1e-6)\n",
        "        sig_plot = np.clip((sig - med) / denom, -8.0, 8.0)\n",
        "\n",
        "        print(f\"[QC] plotting window {w_i} label={label_dbg} channel {ch_i}\")\n",
        "        print(\"     std(raw):\", float(std), \"IQR(raw):\", float(iqr), \"denom_used:\", float(denom))\n",
        "\n",
        "        plt.figure(figsize=(10,4))\n",
        "        plt.plot(t_axis, sig_plot)\n",
        "        plt.xlabel('Time (s)'); plt.ylabel('Robust z-scored amplitude')\n",
        "        plt.title(f'QC window w={w_i} ch={ch_i} label={label_dbg}')\n",
        "        plt.grid(True, ls='--', alpha=0.5); plt.tight_layout()\n",
        "        qc_path = (OUT_DIR / 'qc_window.png').as_posix()\n",
        "        plt.savefig(qc_path, dpi=200); print('[INFO] Saved QC plot to', qc_path)\n",
        "    else:\n",
        "        print('INFO ONLY: No non-flat window/channel found to plot.')\n",
        "else:\n",
        "    print('INFO ONLY: Skipping QC plot; no debug recording found.')\n",
        "\n"
      ],
      "metadata": {
        "id": "cPKXpyvrg1X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save dataset + class balance\n",
        "\n",
        "We save:\n",
        "- `split_windows.npz` with:\n",
        "  - `X`: all aligned windows for this split `[N_total, C_ref, T]`\n",
        "  - `y`: labels `[N_total]`\n",
        "  - `meta`: list of per-recording metadata dicts (coverage ratio, seizure sec, etc.)\n",
        "- `class_balance.png`: simple seizure vs background bar chart.\n"
      ],
      "metadata": {
        "id": "n2JqX0dJg5Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if X_split is not None and y_split is not None:\n",
        "    out_npz_path = OUT_DIR / 'split_windows.npz'\n",
        "    np.savez_compressed(out_npz_path.as_posix(), X=X_split, y=y_split, meta=meta_split)\n",
        "    print('INFO ONLY: Saved NPZ to', out_npz_path.as_posix())\n",
        "\n",
        "    total_windows = len(y_split)\n",
        "    num_bg = int(np.sum(y_split == 0)) if total_windows > 0 else 0\n",
        "    num_sz = int(np.sum(y_split == 1)) if total_windows > 0 else 0\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.bar(['Pre-ictal (1)', 'Negative (0)'], [num_sz, num_bg])\n",
        "    plt.ylabel('Window count')\n",
        "    plt.title('Class distribution in this split')\n",
        "    plt.grid(True, axis='y')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    dist_path = (OUT_DIR / 'class_balance.png').as_posix()\n",
        "    plt.savefig(dist_path, dpi=200)\n",
        "    print('INFO ONLY: Saved class balance bar chart to', dist_path)\n",
        "else:\n",
        "    print('WARNING: Nothing to save / plot class balance (no data).')\n"
      ],
      "metadata": {
        "id": "6DxvbX71g8Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Point this to the OUT_DIR you used in the notebook run for that split\n",
        "LOAD_DIR = Path(\"./tusz_windows\").expanduser().resolve()\n",
        "npz_path = LOAD_DIR / \"split_windows.npz\"\n",
        "\n",
        "print(\"Loading:\", npz_path.as_posix())\n",
        "data = np.load(npz_path, allow_pickle=True)\n",
        "\n",
        "X = data[\"X\"] # shape [N, C_ref, T]\n",
        "y = data[\"y\"] # shape [N]\n",
        "meta_list = data[\"meta\"] # this is an array of Python dicts (dtype=object)\n",
        "\n",
        "print(\"\\n=== DATASET SHAPES ===\")\n",
        "print(\"X.shape:\", X.shape) # (N_win, C_ref, T)\n",
        "print(\"y.shape:\", y.shape) # (N_win,)\n",
        "N, C_ref, T = X.shape if X.size > 0 else (0,0,0)\n",
        "print(f\"N windows = {N}\")\n",
        "print(f\"C_ref (channels after smart canonical) = {C_ref}\")\n",
        "print(f\"T samples per window = {T}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Class balance\n",
        "# -------------------------------------------------\n",
        "num_bg = int(np.sum(y == 0))\n",
        "num_sz = int(np.sum(y == 1))\n",
        "total = len(y)\n",
        "\n",
        "pct_bg = 100.0 * num_bg / total if total > 0 else 0.0\n",
        "pct_sz = 100.0 * num_sz / total if total > 0 else 0.0\n",
        "\n",
        "print(\"\\n=== CLASS BALANCE ===\")\n",
        "print(f\"Negative (0): {num_bg} ({pct_bg:.2f} %)\")\n",
        "print(f\"Pre-Ictal (1): {num_sz} ({pct_sz:.2f} %)\")\n",
        "print(f\"Negative : Pre-Ictal ratio ~ {num_bg}:{num_sz}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Metadata summary\n",
        "# Each element in meta_list corresponds to one *recording* that survived:\n",
        "# - 'recording_id'\n",
        "# - 'fs'\n",
        "# - 'num_windows'\n",
        "# - 'num_seizure_windows'\n",
        "# - 'num_background_windows'\n",
        "# - 'total_seizure_seconds_in_file'\n",
        "# - 'coverage_ratio'\n",
        "# - etc.\n",
        "# -------------------------------------------------\n",
        "\n",
        "print(\"\\n=== PER-RECORDING META (first 10 rows) ===\")\n",
        "for i, m in enumerate(meta_list[:10]):\n",
        "    print(f\"[{i}] rec_id={m.get('recording_id','?')}\")\n",
        "    print(f\" fs_proc={m.get('fs','?')} Hz\")\n",
        "    print(f\" windows={m.get('num_windows','?')} \"\n",
        "          f\"seiz_win={m.get('num_seizure_windows','?')} \"\n",
        "          f\"bg_win={m.get('num_background_windows','?')}\")\n",
        "    print(f\" seizure_time_in_file={m.get('total_seizure_seconds_in_file','?')} sec\")\n",
        "    cov = m.get('coverage_ratio', None)\n",
        "    if cov is not None:\n",
        "        print(f\" coverage={cov*100:.1f}%\")\n",
        "    else:\n",
        "        print(\" coverage=N/A (this was the reference file)\")\n",
        "    print(\"\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Helper to plot one random window from a given class.\n",
        "# We'll choose the channel with the highest std in that window\n",
        "# to avoid plotting a mostly-zero channel.\n",
        "# -------------------------------------------------\n",
        "\n",
        "def plot_random_window(X, y, fs, target_label=1, motion_thresh=1e-6):\n",
        "\n",
        "    idxs = np.where(y == target_label)[0]\n",
        "    if len(idxs) == 0:\n",
        "        print(f\"No windows with label={target_label}\")\n",
        "        return\n",
        "\n",
        "    w_idx = int(random.choice(idxs))\n",
        "    win = X[w_idx] # shape [C_ref, T]\n",
        "\n",
        "    ch_std = np.std(win, axis=1)\n",
        "    ch_i = int(np.argmax(ch_std))\n",
        "    if ch_std[ch_i] <= motion_thresh:\n",
        "        print(f\"Chosen window {w_idx} is too flat (std={ch_std[ch_i]:.2e}). Trying background instead?\")\n",
        "        # we could try fallback logic here, but let's just show anyway\n",
        "    sig = win[ch_i, :]\n",
        "    t = np.arange(sig.shape[0]) / fs\n",
        "\n",
        "    print(f\"window {w_idx}, label={target_label}, chosen channel idx={ch_i}, std={ch_std[ch_i]:.3f}\")\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.plot(t, sig)\n",
        "    plt.xlabel(\"Time (s)\")\n",
        "    plt.ylabel(\"Robust z-scored amplitude\")\n",
        "    plt.title(f\"Random window {w_idx} (label={target_label}) ch={ch_i}\")\n",
        "    plt.grid(True)\n",
        "    plt.autoscale()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------------------------------\n",
        "# We don't store fs directly in X/y, but all aligned data in this split\n",
        "# share the same fs because we either downsampled to TARGET_FS (250)\n",
        "# or left lower fs alone. The metadata for any surviving recording\n",
        "# will tell us. We'll just grab the first one.\n",
        "# -------------------------------------------------\n",
        "if len(meta_list) > 0:\n",
        "    fs_est = meta_list[0].get(\"fs\", TARGET_FS)\n",
        "else:\n",
        "    fs_est = TARGET_FS\n",
        "print(f\"\\nAssumed sampling rate for plotting: {fs_est} Hz\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# Plot example seizure and background windows (if present)\n",
        "# -------------------------------------------------\n",
        "plot_random_window(X, y, fs_est, target_label=1) # seizure\n",
        "plot_random_window(X, y, fs_est, target_label=0) # background"
      ],
      "metadata": {
        "id": "KzCAYDdlhC5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}